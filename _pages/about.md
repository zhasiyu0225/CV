---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm Siyu Zha, an HCI student researcher passionate about Human-AI Collaboration and Creative Learning. Currently, I'm pursuing my PhD in Information Art and Design at the Future Lab of Tsinghua University, under the advisory of Prof. [Yingqing Xu](https://thfl.tsinghua.edu.cn/en/yjdw/yjtd/xyq/index.htm) and now exchange in University of Toronto, under the advisory of Prof. [Jia Xue](https://aij.utoronto.ca/team/dr-jia-xue.html). 

My academic journey began with undergraduate degrees in Automation Engineering and Industrial Design, laying a dual foundation that marries technical precision with aesthetic innovation. My work embodies this cross-disciplinary fusion, particularly evident in projects ranging from AR-enhanced smart mirrors, LLM-based digital well-being management, to 3D LEGO design generations. Each project reflects my commitment to leveraging a blend of engineering precision and design sensitivity, aiming to create technologies that are not only efficient and functional but also accessible and engaging for users.

In spare time I am also a vlogger & content creator on [Xiaohongshu](https://www.xiaohongshu.com/user/profile/5ad8bc90e8ac2b398c6ac4a1) with ~100k subscribers. 

I'm now looking for 2024 summer research opportunities. A complete version of my CV is available [HERE](https://yujia-l.github.io/cv.pdf).

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to UIST 2024</div><img src='images/proj/mirrorcle.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[3D-Mirrorcle: Bridging the Virtual and Real through Depth Alignment in Smart Mirror Systems](https://arxiv.org/pdf/2310.13617.pdf)

**Yujia Liu**, Qi Xin, Chenzhuo Xiang, Yu Zhang, Yingqing Xu.
- In submission to the ACM Symposium on User Interface Software and Technology (UIST), 2024.
- TLDR: An innovative smart mirror system integrating AR with real-world reflections, addressing depth disparity via a lenticular grating setup, with real-time image adjustment and position adaptation algorithms to align AR content with the user's depth perception and enhance interaction realism. Demonstrated through a makeup application prototype with significant improvements in accuracy (11.1% ‚Üë), task completion time (47.9% ‚Üì), and user satisfaction (44.4% ‚Üë) compared to the existing systems.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2024</div><img src='images/proj/mindshift.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention](https://arxiv.org/pdf/2309.16639.pdf)

Ruolan Wu, Chun Yu, Xiaole Pan, **Yujia Liu**, Ningning Zhang, Yue Fu, Yuhan Wang, Zhi Zheng, Li Chen, Qi-aolei Jiang, Xuhai Xu, Yuanchun Shi.
- To appear in the 2024 CHI Conference on Human Factors in Computing Systems (CHI), 2024.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

# üóÇÔ∏è Projects 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/lego.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**3D LEGO Designs Generation and Structural Optimization with Generative Models**
- TLDR: A 3D model generation system combining generative models, stability prediction, and optimization to repurpose unused LEGO bricks, fostering creativity and sustainability. Achieved up to a 42.7% increase in design diversity, a 13.9% increase in user engagement, and a 6.9% improvement in user satisfaction, demonstrating significant advances in interactive design and sustainability.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/music_light.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Adaptive Music and Lighting Systems for Emotional Well-being**
- TLDR: A smart home system that dynamically adjusts music and lighting to nurture inhabitants' emotional well-being, leveraging environmental and color psychology with MER. Capable of responding to and anticipating user emotions and preferences, with a 22.1% enhancement in satisfaction according to a user experience study.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/smart_editing.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Automated Video Editing with Semantic Analysis and Aesthetic Evaluation**
- TLDR: An intelligent video editing framework that integrates video semantic analysis and aesthetic evaluation to com-bine AI with user-centered designs for automating video production tasks. Achieved a 62.5% reduction in editing time, demonstrating the frame-work's effectiveness in improving editing efficiency and output quality.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/phone_color.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Adaptive Image Color Enhancement Across Diverse Displays**
- TLDR: Collected color preferences in digital media via a comprehensive user survey with 89 participants and an expert interview with 24 photographers to identify color preferences across image types & user demographics. Developed a system based on DeepLPF for adaptive image color enhancement under mobile photography scenar-ios, significantly enhanced user satisfaction (12% ‚Üë) in an offline evaluation with 89 participants.
</div>
</div>

# üìñ Educations
- *2022.09 - Now*, Tsinghua University, M.A. in Information Art and Design.
- *2017.08 - 2022.07*, Tsinghua University, B.Eng. in Automation Engineering & B.A. in Industrial Design.

# üíª Internships
- *2022.10 - Now*, Research Assistant @ Tsinghua University Pervasive Interaction Laboratory.
- *2021.07 - 2021.10*, Product Manager Intern @ Huawei, ID/UX Design Group, Cyberverse Product Line.
- *2020.06 - 2020.08*, Algorithm Engineer Intern @ Beijing Ewaybot Technology, Robot Navigation Group.

